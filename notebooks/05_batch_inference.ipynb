{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd75e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05_batch_inference.ipynb\n",
    "\"\"\"\n",
    "Batchâ€¯inference â€“â€¯ChicagoÂ Crime\n",
    "* Usa o melhor modelo salvo em ../dados/best_model\n",
    "* Gera previsÃµes num dataset completo ou em amostras de produÃ§Ã£o\n",
    "* Guarda saÃ­das (parquet + csv) e mÃ©tricas de qualidade\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import pandas as pd, json, os, time\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ config\n",
    "INPUT_PATH   = \"../dados/chicago_ready.parquet\"   # mesmo esquema que no treino\n",
    "MODEL_PATH   = \"../dados/best_model\"              # criado no Stepâ€¯04\n",
    "PRED_PATH    = \"../dados/batch_preds.parquet\"\n",
    "CSV_SAMPLE   = \"../dados/batch_preds_sample.csv\"  # 1â€¯% para quickâ€‘look\n",
    "METRICS_JSON = \"../dados/batch_metrics.json\"\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"Crime_Batch_Inference\")\n",
    "         .getOrCreate())\n",
    "\n",
    "print(\"â‰¡â‰¡ Carregando best model em\", MODEL_PATH)\n",
    "model = PipelineModel.load(MODEL_PATH)\n",
    "\n",
    "df_prod = spark.read.parquet(INPUT_PATH)\n",
    "print(\"â†’ Linhas para inferÃªncia:\", df_prod.count())\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ inferÃªncia\n",
    "print(\"âš™ï¸  Aplicando modeloÂ â€¦\")\n",
    "t0 = time.time()\n",
    "pred = model.transform(df_prod)\n",
    "inf_time = time.time() - t0\n",
    "print(f\"âœ“ InferÃªncia concluÃ­da em {inf_time:.1f}s\")\n",
    "\n",
    "pred.select(\"features\", \"prediction\", \"probability\", \"Arrest\").write.mode(\"overwrite\").parquet(PRED_PATH)\n",
    "print(\"ğŸ“¦ PrevisÃµes salvas em\", PRED_PATH)\n",
    "\n",
    "# 1â€¯% sample CSV para anÃ¡lise manual\n",
    "(pred.select(\"prediction\", \"probability\", \"Arrest\")\n",
    "     .sample(0.01, seed=42)\n",
    "     .toPandas()\n",
    "     .to_csv(CSV_SAMPLE, index=False))\n",
    "print(\"ğŸ“‘ Amostra CSV â†’\", CSV_SAMPLE)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ mÃ©tricas\n",
    "print(\"ğŸ“Š MÃ©tricas batchÂ â€¦\")\n",
    "\n",
    "binary_eval = BinaryClassificationEvaluator(labelCol=\"Arrest\", metricName=\"areaUnderROC\")\n",
    "auc = binary_eval.evaluate(pred)\n",
    "\n",
    "metrics = MulticlassMetrics(pred.select(\"prediction\", \"Arrest\").rdd.map(lambda r: (r[0], r[1])))\n",
    "cm = metrics.confusionMatrix().toArray().tolist()\n",
    "\n",
    "report = {\n",
    "    \"inference_rows\": df_prod.count(),\n",
    "    \"inference_time_s\": inf_time,\n",
    "    \"auc\": auc,\n",
    "    \"confusion_matrix\": cm,\n",
    "}\n",
    "print(json.dumps(report, indent=2))\n",
    "\n",
    "with open(METRICS_JSON, \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "print(\"ğŸ“ MÃ©tricas JSON em\", METRICS_JSON)\n",
    "\n",
    "spark.stop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
